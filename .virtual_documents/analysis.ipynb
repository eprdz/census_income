import numpy as np
import pandas as pd
from scipy.stats import chi2_contingency
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm
from itertools import product
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve
from itertools import chain
import scipy.stats as stats
import warnings
from functools import reduce
import math


df_train = pd.read_csv("./adult.data", header=None)
df_test = pd.read_csv("./adult.test", header=None)


df_train.head()


df_train.columns = ["age", "workclass", "fnlwgt", "education", "education-num", "marital-status", "occupation", "relationship", "race", "sex", "capital_gain", "capital_loss", "hours_per_week", "native_country", "salary"]
df_test.columns = ["age", "workclass", "fnlwgt", "education", "education-num", "marital-status", "occupation", "relationship", "race", "sex", "capital_gain", "capital_loss", "hours_per_week", "native_country", "salary"]


df = pd.concat([df_train, df_test])


X = df.drop(["salary"], axis=1)


y = df.salary


X.head()


y.head()





def analyze_categorical_variables(data):
    """
    Analyzes categorical variables in a DataFrame.

    Args:
        data (DataFrame): The DataFrame containing the data.

    Returns:
        dict: A dictionary where the different categories, their absolute frequencies,
              and relative frequencies are stored.
    """
    # Initialize a dictionary to store the results
    results = {}

    # Generate a list of the variable names
    variables = list(data.columns)

    # Select the numerical columns in the DataFrame
    numerical = data.select_dtypes(include=['int', 'int32', 'int64', 'float', 'float32', 'float64']).columns

    # Select the categorical columns in the DataFrame
    categorical = [variable for variable in variables if variable not in numerical]

    # Iterate through the categorical variables
    for category in categorical:
        # Check if the categorical variable exists in the DataFrame
        if category in data.columns:
            # Create a summary DataFrame for the categorical variable
            summary = pd.DataFrame({
                'n': data[category].value_counts(),                # Count of frequencies
                '%': data[category].value_counts(normalize=True)  # Percentage of frequencies
            })
            results[category] = summary  # Store the summary in the dictionary
        else:
            # If the variable does not exist in the data, store None in the dictionary
            results[category] = None

    return results


def count_unique_values(data):
    """
    Counts unique values in each numeric variable of a DataFrame.

    Args:
        data (DataFrame): The DataFrame containing the data.

    Returns:
        DataFrame: A DataFrame with the variables and the number of unique values in each.
    """
    # Select the numerical columns in the DataFrame
    numerical = data.select_dtypes(include=['int', 'int32', 'int64', 'float', 'float32', 'float64'])

    # Calculate the number of unique values in each numerical column
    results = numerical.apply(lambda x: len(x.unique()))

    # Create a DataFrame with the results
    result = pd.DataFrame({'Column': results.index, 'Unique': results.values})

    return result



def freq_numeric_variables(data, numeric_as_categorical):
    """
    Calculates the frequencies of different values of numeric variables (treated as categorical).
    
    Args:
        data: DataFrame containing the data.
        numeric_as_categorical: List of names of numeric variables to analyze.
    
    Returns:
        dict: A dictionary where the keys are the names of the numeric variables and the values are 
              DataFrames with the summary of frequencies and percentages.
    """
    results = {}

    for variable in numeric_as_categorical:
        # Check if the variable exists in the DataFrame
        if variable in data.columns:
            # Create a summary DataFrame for the variable
            summary = pd.DataFrame({
                'n': data[variable].value_counts(),               # Frequency count
                '%': data[variable].value_counts(normalize=True) # Percentage frequency
            })
            results[variable] = summary  # Store the summary in the dictionary
        else:
            # If the variable doesn't exist in the data, store None in the dictionary
            results[variable] = None

    return results



def missing_pattern(data_input):
    """
    Visualizes a heatmap showing the correlation matrix of missing values in the dataset.

    Args:
        data_input (DataFrame): The input dataset.
    """
    # Calculate a correlation matrix of missing values for columns with at least one missing value
    correlation_matrix = data_input[data_input.columns[data_input.isna().sum() > 0]].isna().corr()
    
    # Create a mask to hide the upper triangle of the matrix (symmetry)
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    
    # Set the figure size and font scale for the plot
    plt.figure(figsize=(8, 6))
    sns.set(font_scale=0.6)
    
    # Generate a heatmap of the missing value correlation matrix
    # 'annot=True' shows the values inside the cells
    # 'cmap="coolwarm"' sets the color palette for the heatmap
    # 'fmt=".2f"' formats the values as floats with two decimal places
    # 'cbar=True' shows the color bar (scale) on the right
    # 'mask=mask' applies the mask to hide the upper triangle
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", cbar=True, mask=mask)
    
    # Set the plot title
    plt.title("Correlation matrix of missing values")
    plt.show()



cat_var = ["workclass", "education", "education-num", "marital-status", "occupation", "relationship", "race", "sex", "native_country"]
cont_var = ["age", "fnlwgt", "capital_gain", "capital_loss", "hours_per_week"]


categorical = analyze_categorical_variables(X)
for key in categorical:
    print(key)
    print(categorical[key])
    print("\n")





print(simplify_workclass)


def simplify_workclass(x):
    x = str(x).strip()
    if x in ["Local-gov", "State-gov", "Federal-gov"]:
        return "Government"
    elif x in ["Self-emp-not-inc", "Self-emp-inc"]:
        return "Self-emp"
    elif x in ["Without-pay", "Never-worked"]:
        return "Other"
    elif x == "Private":
        return "Private"
    elif x == "?":
        return np.nan
    else:
        return np.nan

X["workclass"] = X["workclass"].apply(simplify_workclass)


def simplify_marital_status(x):
    x = str(x).strip()
    if x in ["Divorced", "Separated", "Widowed", "Married-spouse-absent", "Married-AF-spouse"]:
        return "Before-Married"
    else:
        return x

X["marital-status"] = X["marital-status"].apply(simplify_marital_status)
    
education_mapping = {
    "Preschool": "Elementary",
    "1st-4th": "Elementary",
    "5th-6th": "Elementary",
    "7th-8th": "Elementary",
    
    "9th": "MiddleHS",
    "10th": "MiddleHS",
    "11th": "MiddleHS",
    "12th": "MiddleHS",
    
    "HS-grad": "HS-grad",
    
    "Some-college": "PostHS",
    "Assoc-voc": "PostHS",
    "Assoc-acdm": "PostHS",
    
    "Bachelors": "HigherEd",
    "Prof-school": "HigherEd",
    "Masters": "HigherEd",
    "Doctorate": "HigherEd"
}

X["education_grouped"] = X["education"].apply()map(education_mapping)


X["education"].unique()


X["education_grouped"]








freq_numeric_variables(X, cont_var)








X.replace('?', np.nan, inplace=True)
X.replace(' ?', np.nan, inplace=True)


missing_pattern(X)
